{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import sexmachine.detector as gender\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import cross_validation \n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-21d52edc6066>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-21d52edc6066>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \"\"\" Reads users profile from csv files \"\"\"\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    " def read_datasets():\n",
    "\"\"\" Reads users profile from csv files \"\"\"\n",
    "    genuine_users = pd.read_csv(\"data/not_fake_comments.csv\")\n",
    "    fake_users = pd.read_csv(\"data/fake_comments.csv\") \n",
    "    # print genuine_users.columns\n",
    "    # print genuine_users.describe()\n",
    "    #print fake_users.describe()\n",
    "    x=pd.concat([genuine_users,fake_users])\n",
    "    y=len(fake_users)*[0] + len(genuine_users)*[1] \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    lang_list = list(enumerate(np.unique(x['lang'])))\n",
    "    lang_dict = { name : i for i, name in lang_list }\n",
    "    x.loc[:,'lang_code'] = x['lang'].map( lambda x: lang_dict[x]).astype(i nt)\n",
    "    feature_columns_to_use = ['statuses_count','followers_count','friend s_count','favourites_count','listed_count','lang_code']\n",
    "    x=x.loc[:,feature_columns_to_use] return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator,title,X,y,ylim=None,cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure() plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        plt.xlabel(\"Training examples\")\n",
    "        plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes) train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1) plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "    label=\"Cross-validation score\") plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,title='Confusionmatrix',cmap=plt.cm.Blue s):\n",
    "    target_names=['Fake','Genuine']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names) \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test,y_pred):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    print \"False Positive rate: \",false_positive_rate\n",
    "    print \"True Positive rate: \",true_positive_rate\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right') plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2]) plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate') plt.xlabel('False Positive Rate') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test):\n",
    "    \"\"\" Trains and predicts dataset with a SVM classifier \"\"\" # Scaling features\n",
    "    X_train=preprocessing.scale(X_train) \n",
    "    X_test=preprocessing.scale(X_test)\n",
    "    Cs = 10.0 ** np.arange(-2,3,.5)\n",
    "    gammas = 10.0 ** np.arange(-2,3,.5)\n",
    "    param = [{'gamma': gammas, 'C': Cs}]\n",
    "    cvk = StratifiedKFold(y_train,n_folds=5)\n",
    "    classifier = SVC()\n",
    "    clf = GridSearchCV(classifier,param_grid=param,cv=cvk)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"The best classifier is: \",clf.best_estimator_) \n",
    "    clf.best_estimator_.fit(X_train,y_train)\n",
    "    # Estimate score\n",
    "    scores = cross_validation.cross_val_score(clf.best_estimator_, X_train,y_train, cv=5)\n",
    "    print scores\n",
    "    print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.st d() / 2))\n",
    "    title = 'Learning Curves (SVM, rbf kernel, $\\gamma=%.6f$)' %clf.best_e stimator_.gamma\n",
    "    plot_learning_curve(clf.best_estimator_, title, X_train, y_train, c v=5)\n",
    "    plt.show()\n",
    "    # Predict class\n",
    "    y_pred = clf.best_estimator_.predict(X_test) return y_test,y_pred\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print\"readingdatasets.....\\n\" \n",
    "x,y=read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print\"extractingfeatues.....\\n\" \n",
    "x=extract_features(x)\n",
    "print x.columns print x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print\"splitingdatasetsintrainandtestdataset...\\n\" \n",
    "X_train,X_test,y_train,y_test = train_test_split(x, y, test_size=0.20, ran dom_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print\"trainingdatasets.......\\n\"\n",
    "y_test,y_pred = train(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print'ClassificationAccuracyonTestdataset:',accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred) \n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_normalized=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis] \n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred,target_names=['Fake','Genuin e']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
